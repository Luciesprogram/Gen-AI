{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "authorship_tag": "ABX9TyOd/GIzDGyBeLbM33ZsGD6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luciesprogram/Gen-AI/blob/main/RAG_Application_using_Langchain_Mistral_and_Weviate_P3_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface langchain-weaviate weaviate-client langchain-text-splitters pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzHztAWQDwVa",
        "outputId": "a4cb8746-5a0b-4438-9da6-bccaa3ea5886"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-weaviate\n",
            "  Downloading langchain_weaviate-0.0.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.19.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Collecting langchain-text-splitters\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.33.4)\n",
            "Collecting langchain-core<2.0.0,>=1.2.0 (from langchain-huggingface)\n",
            "  Downloading langchain_core-1.2.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-weaviate) (2.0.2)\n",
            "Requirement already satisfied: simsimd<7.0.0,>=6.2.1 in /usr/local/lib/python3.11/dist-packages (from langchain-weaviate) (6.5.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Collecting validators<1.0.0,>=0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting authlib<2.0.0,>=1.6.5 (from weaviate-client)\n",
            "  Downloading authlib-1.6.6-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pydantic<3.0.0,>=2.12.0 (from weaviate-client)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<1.80.0,>=1.59.5 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.73.1)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (5.29.5)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from weaviate-client)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.6.5->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->weaviate-client) (24.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.1.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (8.5.0)\n",
            "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.0->langchain-huggingface)\n",
            "  Downloading uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.12.0->weaviate-client) (0.7.0)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.12.0->weaviate-client)\n",
            "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.12.0->weaviate-client)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.6.5->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.6.5->weaviate-client) (2.22)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_weaviate-0.0.6-py3-none-any.whl (10 kB)\n",
            "Downloading weaviate_client-4.19.0-py3-none-any.whl (603 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.5/603.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.6/329.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading authlib-1.6.6-py2.py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.0/244.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading langchain_core-1.2.4-py3-none-any.whl (477 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.4/477.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.7/343.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, uuid-utils, typing-inspection, pypdf, pydantic-core, deprecation, pydantic, authlib, weaviate-client, langchain-core, langchain-weaviate, langchain-text-splitters, langchain-huggingface\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.1\n",
            "    Uninstalling typing-inspection-0.4.1:\n",
            "      Successfully uninstalled typing-inspection-0.4.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.68\n",
            "    Uninstalling langchain-core-0.3.68:\n",
            "      Successfully uninstalled langchain-core-0.3.68\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.31.0 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
            "langchain 0.3.26 requires langchain-core<1.0.0,>=0.3.66, but you have langchain-core 1.2.4 which is incompatible.\n",
            "langchain 0.3.26 requires langchain-text-splitters<1.0.0,>=0.3.8, but you have langchain-text-splitters 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.6.6 deprecation-2.1.0 langchain-core-1.2.4 langchain-huggingface-1.2.0 langchain-text-splitters-1.1.0 langchain-weaviate-0.0.6 pydantic-2.12.5 pydantic-core-2.41.5 pypdf-6.5.0 typing-inspection-0.4.2 uuid-utils-0.12.0 validators-0.35.0 weaviate-client-4.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import locale\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "rrIPbs8NDxD6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "G5PcKBTMDzxc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEAVIATE_CLUSTER = userdata.get('WEAVIATE_CLUSTER')\n",
        "WEAVIATE_API_KEY = userdata.get('WEAVIATE_API_KEY')\n",
        "hf_token = userdata.get('HUGGINGFACE_API_TOKEN')"
      ],
      "metadata": {
        "id": "T8VmOMzOD3cZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "RS8_wJAWD7D1"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from langchain_weaviate import WeaviateVectorStore"
      ],
      "metadata": {
        "id": "M6LdckVlEDib"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_CLUSTER,\n",
        "    auth_credentials=weaviate.auth.AuthApiKey(WEAVIATE_API_KEY)\n",
        ")"
      ],
      "metadata": {
        "id": "To_HTS7PEHd5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = WeaviateVectorStore(\n",
        "    client=client,\n",
        "    index_name=\"RAG_Notebook_Collection\", # Collection name\n",
        "    embedding=embeddings,\n",
        "    text_key=\"text\"\n",
        ")"
      ],
      "metadata": {
        "id": "BRbsSSEyEJe5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5m8MZK-FOcF",
        "outputId": "cd2649ef-822d-4ad7-e0c3-488fefcb0cde"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.2.4)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.5)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "bnbqsdRpEKMg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/2005.11401v4.pdf\", extract_images=True)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "YzR8GmppENDg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "5IkJrhryEOyq"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs:\n",
        "    # Create a copy of keys to avoid 'dictionary changed size during iteration' errors\n",
        "    bad_keys = [k for k in doc.metadata.keys() if \".\" in k]\n",
        "    for key in bad_keys:\n",
        "        # Replace dot with underscore or just delete the property\n",
        "        new_key = key.replace(\".\", \"_\")\n",
        "        doc.metadata[new_key] = doc.metadata.pop(key)"
      ],
      "metadata": {
        "id": "v1PTnjTaGZa1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db.add_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge0XRJ3_ERDF",
        "outputId": "1206607e-698a-4add-a6bd-0aaffcba9501"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bc23a272-4cdf-4e5e-b37f-4c8c5e100ef4',\n",
              " 'f99681c5-f4a1-43f3-b033-9283186d6f20',\n",
              " 'a5c7bb8b-4c2f-42cb-8dc5-f17238e71358',\n",
              " 'f02df0ec-df7a-4f41-b406-061b8ed95dee',\n",
              " '3126ac1f-9fdd-417d-b74b-650542fab5fc',\n",
              " 'f9d88641-c1e4-477a-a4c0-47d9d74c84ec',\n",
              " '34d41292-8784-4609-823a-f91011056de5',\n",
              " 'e5baaa8a-2e82-499f-be77-d9873fe22f2f',\n",
              " '41c076d5-f63e-4fc1-8638-8a1c9270f129',\n",
              " '0e7f4e12-d609-4799-b5f7-a1e187a57e3f',\n",
              " 'd8e0579e-249e-4be8-a7d3-b1831cd578bf',\n",
              " '76c93569-466e-469c-afc4-bf657f9b5e4b',\n",
              " '8b376242-a445-4d34-8835-ccd11a6cd412',\n",
              " 'e6909623-b778-4721-af16-3964ac372722',\n",
              " 'ac618a90-8485-4701-942e-fef070097e4c',\n",
              " '844956d2-3503-4373-b434-3cc503245088',\n",
              " 'cb3372c1-f9f4-49d6-9738-c557f27f30f4',\n",
              " '183ce8da-a075-4a63-9f4c-f26979045635',\n",
              " '189f913c-0f40-4652-88bb-5ed096c0e7ae',\n",
              " '6e1e5853-23f3-4501-b46b-c4d5f29b6825',\n",
              " '98ec35d4-9df2-470d-b521-72a688d7a0ed',\n",
              " 'f7de1a6e-4e6f-4d36-aa5a-dd19345484b4',\n",
              " '364e396f-d5b2-4afb-b7a8-1e9e7de14ff9',\n",
              " '313d5296-3eba-4620-bd26-58c97fa2f923',\n",
              " '5c405317-2987-4b4e-ae3b-8236cc796185',\n",
              " 'd79bab6d-7e51-4827-ba60-121de0aa624a',\n",
              " 'd15e8bdc-b99d-4216-94dc-13ec2bc6fb2e',\n",
              " '45db2496-652c-4f25-bf1b-b8e30465eed4',\n",
              " '97ccb153-c570-4bef-b20f-924e5daabd33',\n",
              " '50ac874d-179a-4c9f-bc1d-d8b7ec50b62b',\n",
              " '78839104-2970-4979-89b0-d148410120af',\n",
              " '4da10391-7c05-40d3-9be3-f18be90e5c79',\n",
              " 'f4a62578-1964-4be3-9300-08acd3e217cb',\n",
              " '288917b1-4fc6-45ce-b2cc-0d1570982bd5',\n",
              " '2079ba7c-db89-408d-b718-fe210f02bbe4',\n",
              " '185567ae-7a17-4e6c-b743-5c1b9679ca45',\n",
              " '06532389-2bd5-4bbe-b2f2-1b871d71b79e',\n",
              " '619c47cc-51ee-4365-99f6-ff0d6920ca3e',\n",
              " '1beab4a6-5430-4465-8e3a-85cb1a1ab221',\n",
              " '59be297c-a631-411e-a8f6-90743a03e930',\n",
              " '1f62102f-4229-4cea-85b3-f4b94162573f',\n",
              " '36bbde7e-95d6-444c-b49b-d79c581f3c1c',\n",
              " '6bf48168-5b64-4b0b-b473-b9aecbafaa1e',\n",
              " '6f5ec118-8e64-4a20-a4ec-61e268dda0d3',\n",
              " '280cd7e4-6a76-4c5c-825a-dbc77016cb37',\n",
              " 'f03e7e01-4619-474b-977f-c6685085a0ef',\n",
              " '67a2d0b7-8d79-437b-912c-99db35fa4107',\n",
              " '5ce969c3-43cc-4093-a457-a7e0af7077d3',\n",
              " 'f4f72791-0572-4e7d-aae8-9265ddc4c328',\n",
              " 'ea2279d6-02c8-4afa-9fbb-f3731e4dcd0a',\n",
              " '8d56ae80-cfed-41a0-b5a9-10ec61ee1b80',\n",
              " 'b2fe2e6b-c381-40e8-9340-a5ba30df9594',\n",
              " '5f2a0357-e722-456a-b4d7-4d70219aa7bb',\n",
              " 'a496db9b-b29d-40a8-b5c0-a3542b71624f',\n",
              " '578a54ee-18f2-4386-a3a5-eeee206832f6',\n",
              " '3dac224d-fed7-4c3a-8011-d1aa2154ed9b',\n",
              " 'b37e4bd8-4f28-49b2-b6e0-1c14442767c2',\n",
              " 'bd55ab2b-7ccc-446f-8888-5f07d4463493',\n",
              " '26bb64e9-2496-4dcf-9f27-48e0a2974846',\n",
              " '86963cd9-db07-4de0-88e6-a694b0a309b0',\n",
              " '474dbc03-ded4-4b57-8c98-ce944aee85a9',\n",
              " 'ee28bfc2-7fda-4eb4-923f-38cfcd82c953',\n",
              " 'a59d4f66-ee50-4ce4-b0ba-a4f81cbe18c3',\n",
              " '7d097786-480f-438b-ae6d-be39c5c38e53',\n",
              " '054c672c-5fd3-4124-bda4-be3eea9fd8fb',\n",
              " '7e8c95cf-b163-4701-a02c-86d9e943eaef',\n",
              " '775d9d40-3b21-40b7-9f55-fe1552f54393',\n",
              " 'e9aa9c66-382a-4ba4-9f14-c5baa198bafd',\n",
              " '25b113a7-bc6c-4114-be85-a809e9600ddb',\n",
              " '40dc0919-c853-4c29-b7d1-443bb1128fd8',\n",
              " 'ed63b0d9-2534-44e1-98cf-643ddf8e103c',\n",
              " '2cea2498-9151-4540-bb87-f88a4594d08b',\n",
              " '28a43d03-ae32-485d-a095-2c3fe8477a2a',\n",
              " '05fd08ef-e042-43cb-abf4-e623e1244801',\n",
              " '0e202bed-8342-4f9e-a81d-23df0bcc8dc8',\n",
              " '4e7f8aef-78e0-40e2-b599-1a076f98f9b5',\n",
              " '4d04e877-fe29-45ed-a09d-dfa740f8c2af',\n",
              " 'e7053f41-3b3b-4f54-9be8-7f90c5b53bff',\n",
              " 'c387ab54-9930-47d4-875b-2f78594a87ae',\n",
              " '5c94a93e-c4c0-4f29-acf2-22fc8a2feb71',\n",
              " 'f40e1eaf-1be5-43bf-8cc2-d28de4f059e6',\n",
              " '62047c07-a4d8-4fd0-8f71-379f3ec30027',\n",
              " '6b778365-cafc-40de-bd84-64e4bc67f0ab']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "i4AQr2WVES2K"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "wtJZ_UIDHfxO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    huggingfacehub_api_token=hf_token,\n",
        "    temperature=0.2,\n",
        "    max_new_tokens=256,\n",
        ")"
      ],
      "metadata": {
        "id": "nBpDAJ52EUxO"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "QtV-T-pkHbGr"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant for question-answering tasks. Use the context to answer.\"),\n",
        "    (\"human\", \"Context: {context}\\n\\nQuestion: {question}\")\n",
        "    ])"
      ],
      "metadata": {
        "id": "4m3Ik3hLEXBu"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": vector_db.as_retriever(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | chat_model # Use the chat_model wrapper here!\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "0rsCMMw6EbsN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"What is Retrieval-Augmented Generation (RAG)?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63uBvcBPEdZU",
        "outputId": "46c2106f-0dec-41e7-8557-23dec94c2ed1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Retrieval-Augmented Generation (RAG) is a model for knowledge-intensive natural language processing tasks that uses a retrieval component to gather relevant information from a large corpus before generating an answer or text. The model combines parametric and non-parametric memory to obtain state-of-the-art results on open-domain question answering. RAG models have been shown to obtain more factual and specific generations than purely parametric models, and the learned retrieval component has been validated to be effective. The retrieval index can be hot-swapped to update the model without requiring any retraining. RAG models use retrieved documents to generate more diverse and informative responses than baseline models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rag_chain.invoke(\"How does the RAG model differ from traditional language generation models?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcmioZL2GGwG",
        "outputId": "29f7a499-ae5c-4115-ea9e-9ce07e58ba61"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The RAG model differs from traditional language generation models in several ways, as described in the context:\n",
            "\n",
            "1. Access to Gold Passages: Traditional language generation models often have access to gold passages with specific information required to generate the reference answer. In contrast, the RAG model does not have access to these gold passages and must generate answers based on the given question alone.\n",
            "2. Unanswerable Questions: Many questions in the datasets used to evaluate the models are unanswerable without the gold passages. The RAG model is able to handle these questions and generate appropriate responses, while traditional models may struggle or fail.\n",
            "3. Answers from Wikipedia: Not all questions are answerable from Wikipedia alone. Traditional models may rely heavily on the gold passages to generate accurate answers, while the RAG model is able to generate answers based on the given question and its knowledge base, even if the question cannot be answered directly from Wikipedia.\n",
            "4. Performance: The RAG model outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points, indicating that it generates answers that are more similar to the gold answers and are more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "3qnJaPhGJuHm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(text):\n",
        "  return Markdown(textwrap.indent(rag_chain.invoke(text), '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "yrMzhDVkJ3Zu"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen(\"what is RAG Sequence model, its formula and its is based on which mathematical concept\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "zYxHfddmLBb9",
        "outputId": "6fe2d48a-0794-45bc-e76e-b7880b37e3fc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The RAG Sequence model is a generative model for question answering that uses a retriever to identify the top K relevant documents and a generator to produce the answer sequence based on the retrieved documents. The formula for the RAG Sequence model is given by:\n> \n> p(y|x) ≈ ∑z∈top-k(p(z|x))pη(z|x)pθ(y|x,z,y 1:i-1)\n> \n> Here, x is the input question, y is the output sequence of tokens, z is a latent document, p(z|x) is the probability of document z given the input question x, pη(z|x) is the probability of the document z being in the top K retrieved documents, and pθ(yi|x,z,y 1:i-1) is the probability of the ith token in the output sequence y given the input question x, the latent document z, and the previous tokens in the output sequence y 1:i-1.\n> \n> The RAG Sequence model is based on the concept of sequence generation using a probabilistic model. It uses a gener"
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQG12UlqLfNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}